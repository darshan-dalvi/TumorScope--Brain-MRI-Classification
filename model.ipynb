{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TumorScope Brain MRI Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale =1/255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2870 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('image_dataset/Training',\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glioma_tumor': 0, 'meningioma_tumor': 1, 'no_tumor': 2, 'pituitary_tumor': 3}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 377 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale= 1/255)\n",
    "\n",
    "test_set =test_datagen.flow_from_directory('image_dataset/Testing',\n",
    "                                           target_size=(64, 64),\n",
    "                                           class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling - CNN\n",
    "Initilising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1 - Convolution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "classifier.add(Conv2D(input_shape=[64,64,3],\n",
    "                      filters=32, kernel_size=3,\n",
    "                      activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2 - Max Pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D\n",
    "classifier.add(MaxPooling2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3 -Flattening**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4 - Full Connection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "# Hidden layers with 128 units and ReLU activation\n",
    "classifier.add(Dense(units = 64, activation='relu'))\n",
    "\n",
    "# Output layer with 1 unit and softmax activation\n",
    "classifier.add(Dense(units = 4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the CNN Model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer= 'adam',\n",
    "                   loss = 'categorical_crossentropy',\n",
    "                   metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n",
      "90/90 [==============================] - 6s 67ms/step - loss: 1.1779 - accuracy: 0.4826 - val_loss: 1.4870 - val_accuracy: 0.4005\n",
      "Epoch 2/55\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.8764 - accuracy: 0.6491 - val_loss: 1.6692 - val_accuracy: 0.4562\n",
      "Epoch 3/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.7330 - accuracy: 0.7045 - val_loss: 1.8779 - val_accuracy: 0.5385\n",
      "Epoch 4/55\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.6441 - accuracy: 0.7463 - val_loss: 1.9835 - val_accuracy: 0.5464\n",
      "Epoch 5/55\n",
      "90/90 [==============================] - 6s 69ms/step - loss: 0.5873 - accuracy: 0.7714 - val_loss: 1.7743 - val_accuracy: 0.5570\n",
      "Epoch 6/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.5410 - accuracy: 0.7861 - val_loss: 2.1762 - val_accuracy: 0.5358\n",
      "Epoch 7/55\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 0.5310 - accuracy: 0.7955 - val_loss: 1.8665 - val_accuracy: 0.6127\n",
      "Epoch 8/55\n",
      "90/90 [==============================] - 6s 61ms/step - loss: 0.4808 - accuracy: 0.8125 - val_loss: 1.8530 - val_accuracy: 0.6472\n",
      "Epoch 9/55\n",
      "90/90 [==============================] - 6s 71ms/step - loss: 0.4541 - accuracy: 0.8240 - val_loss: 2.3086 - val_accuracy: 0.6233\n",
      "Epoch 10/55\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.4339 - accuracy: 0.8314 - val_loss: 2.0072 - val_accuracy: 0.6817\n",
      "Epoch 11/55\n",
      "90/90 [==============================] - 6s 65ms/step - loss: 0.4157 - accuracy: 0.8394 - val_loss: 2.0294 - val_accuracy: 0.6472\n",
      "Epoch 12/55\n",
      "90/90 [==============================] - 6s 68ms/step - loss: 0.3916 - accuracy: 0.8540 - val_loss: 2.1396 - val_accuracy: 0.6844\n",
      "Epoch 13/55\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3903 - accuracy: 0.8446 - val_loss: 2.1371 - val_accuracy: 0.6233\n",
      "Epoch 14/55\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3851 - accuracy: 0.8498 - val_loss: 2.4796 - val_accuracy: 0.6790\n",
      "Epoch 15/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.3287 - accuracy: 0.8714 - val_loss: 2.5770 - val_accuracy: 0.6525\n",
      "Epoch 16/55\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.3187 - accuracy: 0.8774 - val_loss: 2.2771 - val_accuracy: 0.6950\n",
      "Epoch 17/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.3278 - accuracy: 0.8777 - val_loss: 2.3341 - val_accuracy: 0.7082\n",
      "Epoch 18/55\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.2913 - accuracy: 0.8885 - val_loss: 2.5882 - val_accuracy: 0.7241\n",
      "Epoch 19/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.2824 - accuracy: 0.8930 - val_loss: 2.6627 - val_accuracy: 0.7029\n",
      "Epoch 20/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.2926 - accuracy: 0.8892 - val_loss: 2.5497 - val_accuracy: 0.6844\n",
      "Epoch 21/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.2754 - accuracy: 0.8930 - val_loss: 2.7034 - val_accuracy: 0.6897\n",
      "Epoch 22/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.2485 - accuracy: 0.9098 - val_loss: 3.0067 - val_accuracy: 0.6870\n",
      "Epoch 23/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.2534 - accuracy: 0.9080 - val_loss: 2.8247 - val_accuracy: 0.6950\n",
      "Epoch 24/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.2414 - accuracy: 0.9084 - val_loss: 2.6372 - val_accuracy: 0.7188\n",
      "Epoch 25/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.2207 - accuracy: 0.9167 - val_loss: 2.7577 - val_accuracy: 0.7215\n",
      "Epoch 26/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.2024 - accuracy: 0.9282 - val_loss: 2.8388 - val_accuracy: 0.7374\n",
      "Epoch 27/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.2180 - accuracy: 0.9202 - val_loss: 2.6394 - val_accuracy: 0.7427\n",
      "Epoch 28/55\n",
      "90/90 [==============================] - 6s 61ms/step - loss: 0.1869 - accuracy: 0.9303 - val_loss: 3.1334 - val_accuracy: 0.7003\n",
      "Epoch 29/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.1804 - accuracy: 0.9369 - val_loss: 3.1596 - val_accuracy: 0.7215\n",
      "Epoch 30/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.1736 - accuracy: 0.9366 - val_loss: 2.5855 - val_accuracy: 0.7666\n",
      "Epoch 31/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.1692 - accuracy: 0.9401 - val_loss: 2.7765 - val_accuracy: 0.7480\n",
      "Epoch 32/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.1725 - accuracy: 0.9359 - val_loss: 3.2394 - val_accuracy: 0.7215\n",
      "Epoch 33/55\n",
      "90/90 [==============================] - 6s 61ms/step - loss: 0.1761 - accuracy: 0.9373 - val_loss: 2.8240 - val_accuracy: 0.7188\n",
      "Epoch 34/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.1457 - accuracy: 0.9498 - val_loss: 2.7319 - val_accuracy: 0.7454\n",
      "Epoch 35/55\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.1468 - accuracy: 0.9502 - val_loss: 2.9689 - val_accuracy: 0.7347\n",
      "Epoch 36/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.1368 - accuracy: 0.9509 - val_loss: 2.9190 - val_accuracy: 0.7401\n",
      "Epoch 37/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.1502 - accuracy: 0.9401 - val_loss: 3.2207 - val_accuracy: 0.7454\n",
      "Epoch 38/55\n",
      "90/90 [==============================] - 6s 66ms/step - loss: 0.1482 - accuracy: 0.9422 - val_loss: 3.1946 - val_accuracy: 0.7533\n",
      "Epoch 39/55\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.1484 - accuracy: 0.9425 - val_loss: 3.0817 - val_accuracy: 0.7321\n",
      "Epoch 40/55\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.1225 - accuracy: 0.9578 - val_loss: 3.5375 - val_accuracy: 0.7321\n",
      "Epoch 41/55\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.1306 - accuracy: 0.9516 - val_loss: 2.6244 - val_accuracy: 0.7666\n",
      "Epoch 42/55\n",
      "90/90 [==============================] - 6s 65ms/step - loss: 0.1488 - accuracy: 0.9467 - val_loss: 2.9871 - val_accuracy: 0.7666\n",
      "Epoch 43/55\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.1092 - accuracy: 0.9624 - val_loss: 3.3826 - val_accuracy: 0.7480\n",
      "Epoch 44/55\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.1062 - accuracy: 0.9638 - val_loss: 3.3873 - val_accuracy: 0.7666\n",
      "Epoch 45/55\n",
      "90/90 [==============================] - 6s 64ms/step - loss: 0.1099 - accuracy: 0.9620 - val_loss: 3.1233 - val_accuracy: 0.7639\n",
      "Epoch 46/55\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.1075 - accuracy: 0.9613 - val_loss: 3.1000 - val_accuracy: 0.7427\n",
      "Epoch 47/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.1097 - accuracy: 0.9613 - val_loss: 3.3845 - val_accuracy: 0.7825\n",
      "Epoch 48/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.1145 - accuracy: 0.9582 - val_loss: 4.0988 - val_accuracy: 0.7427\n",
      "Epoch 49/55\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.1077 - accuracy: 0.9638 - val_loss: 3.4665 - val_accuracy: 0.7480\n",
      "Epoch 50/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.1006 - accuracy: 0.9676 - val_loss: 3.2369 - val_accuracy: 0.7745\n",
      "Epoch 51/55\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.0968 - accuracy: 0.9655 - val_loss: 3.5224 - val_accuracy: 0.7480\n",
      "Epoch 52/55\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.0844 - accuracy: 0.9742 - val_loss: 4.0931 - val_accuracy: 0.7188\n",
      "Epoch 53/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.0918 - accuracy: 0.9655 - val_loss: 3.4439 - val_accuracy: 0.7613\n",
      "Epoch 54/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.0752 - accuracy: 0.9767 - val_loss: 3.8658 - val_accuracy: 0.7560\n",
      "Epoch 55/55\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.0891 - accuracy: 0.9634 - val_loss: 3.8574 - val_accuracy: 0.7613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e3a26679d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(\n",
    "    x=training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=55\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalution\n",
    "- Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "The image is a Meningioma Tumor\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "The image is a Meningioma Tumor\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model (adjust the path to your model)\n",
    "classifier = load_model('path_to_your_model.h5')  # Replace with your model's path\n",
    "\n",
    "# Streamlit Web App Interface\n",
    "st.title(\"Brain Tumor MRI Classification\")\n",
    "st.write(\"Upload an MRI image to classify the tumor type.\")\n",
    "\n",
    "# File uploader\n",
    "uploaded_image = st.file_uploader(\"Choose an MRI image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "if uploaded_image is not None:\n",
    "    # Open the uploaded image\n",
    "    test_image = Image.open(uploaded_image)\n",
    "    \n",
    "    # Data Preprocessing\n",
    "    test_image = test_image.resize((64, 64))  # Resize to match the model's input size\n",
    "    test_image = np.array(test_image)  # Convert image to numpy array\n",
    "    test_image = test_image / 255.0  # Normalize the image (if this was done during training)\n",
    "    test_image = np.expand_dims(test_image, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Prediction\n",
    "    result = classifier.predict(test_image)\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class = np.argmax(result, axis=1)\n",
    "\n",
    "    # Display the result\n",
    "    if predicted_class == 0:\n",
    "        st.image(uploaded_image, caption=\"Glioma Tumor\", use_column_width=True)\n",
    "        st.write(\"The image is classified as a Glioma Tumor.\")\n",
    "    elif predicted_class == 1:\n",
    "        st.image(uploaded_image, caption=\"Meningioma Tumor\", use_column_width=True)\n",
    "        st.write(\"The image is classified as a Meningioma Tumor.\")\n",
    "    elif predicted_class == 2:\n",
    "        st.image(uploaded_image, caption=\"No Tumor\", use_column_width=True)\n",
    "        st.write(\"The image is classified as No Tumor.\")\n",
    "    else:\n",
    "        st.image(uploaded_image, caption=\"Pituitary Tumor\", use_column_width=True)\n",
    "        st.write(\"The image is classified as a Pituitary Tumor.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "classifier.save('brain_tumor_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
